---
layout: single
title:  "Matrix Factorization Technique for Recommender System"
typora-root-url: ../
categories: study
published: true
tag: [Recommend System, python, study]
toc: true
author_profile: false
sidebar: 
nav: "docs"
---
# [논문 리뷰 스터디 2] Recommand System

추천시스템은 유저와 아이템의 주변정보와 상호작용 기록을 바탕으로 유저가 선호할 아이템을 예측하여 유저의 의사결정을 돕는 인공지능 서비스이며, 아래와 같은 특징을 가지고 있다.

- 유저의 측면에서 원하는 것을 빠르게 찾을 수 있음
- 기업 측면에서는 고객 이탈을 막고, 반응 고객을 찾아내어 매출을 올릴 수 있음
- 행동패턴, 구매패턴, 메타 정보 활용
- 후보 생성, 순위 매기기, 재정렬의 파이프라인을 가짐

추천시스템 관련 논문 중 오늘 리뷰할 논문은 "Matrix Factorization Technique for Recommender System"이다.
(논문 출처: https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf)

해당 논문에서 제시한 방식은 **협업 필터링**을 이용한 방법으로 사용자의 과거 경험과 행동 방식을 기반으로 한다. 따라서 과거 경험이 없는 경우 사용할 수 없다는 단점이 존재한(이를 보완하여 고안된 방법은 Factorization Machine). 협업 필터링은 잠재요인 모델과 근접 이웃 방법이 있으며 본 논문에서는 잠재요인 모델을 사용하였다. 

행렬 분해를 통하여 사용자의 과거 경험 데이터에서 패턴을 찾아내는데, 이를 적절하게 추청할 경우 주어진 데이터에서는 알 수 없던 숨겨진 특징을 발견할 수 있는 것으로 알려져 있다.
 
# 1. 행렬 분해 
각 유저가 아이템에 대해 매긴 평점, 혹은 구매/ 클릭 여부를 나타낸 행렬을 **Interaction Matrix**라고 하는데, 행렬에 유저의 직접적/ 간접적인 선호가 드러나 있다.

![image](https://github.com/yujinp0/yujinp0.github.io/assets/138744622/7a3cffa4-fa4a-4114-aafb-994bbc4f7cf9){: width="70%" height="70%"}{: .align-center}

출처: https://buomsoo-kim.github.io/data/images/2020-09-25/0.png

**Interaction Matrix**를 **User Latent Factor**와 **Item Latent Factor** 분해하는 것을 **Matrix Factorization**라고 한다. **Factorization을** 통하여 행렬을 저차원의 행렬로 쪼개어 연산의 효율성을 확보할 수 있으며, 노이즈를 줄이고 데이터를 압축하는 방향으로 계산하기 때문에 얻고자 하는 중요한 패턴에 집중할 수 있다는 이점이 있다. 

![image](https://github.com/yujinp0/yujinp0.github.io/assets/138744622/50797d70-dfa3-44d4-bcd7-e1572125216b)

출처: https://buomsoo-kim.github.io/data/images/2020-09-25/1.png{: width="70%" height="70%"}{: .align-center}

![image](https://github.com/yujinp0/yujinp0.github.io/assets/138744622/afc20204-8833-40de-9e61-ba3b70f2cbe4){: width="70%" height="70%"}{: .align-center}

출처: https://miro.medium.com/v2/resize:fit:720/format:webp/1*xMxQL_V9CWeLggrk-Uyzmg.png

# 2. 목표 함수

$$\min_{P, Q} \sum_{u,i \in k }^b (r_{ui}-p^T_uq_i)^2 + \lambda({||p_u||^2}+{||q_i||^2})$$

 - $u, i \in T$: user, item in Training Set
 - $r_ui$(ture rating)는 유저 u의 아이템 i에 대한 평점
 - $p^T_uq_i$(predictedr rating)는 행렬 P와 Q에서 가져온 유저 u와 아이템 i에 대한 latent factor
 - $\lambda({||p_u||^2}+{||q_i||^2})$ regularization term으로 행렬의 값이 너무 커지지 않도록 하는 역할을 함


# 3. 최적화
손실함수를 최적화 하는 방법에는 **Stochastic Gradient Descent(SGD) 방법**과 **Alternating Least Squres(ALS) 방법**을 제시하고 있다.

## SGD
Gradient를 조금씩 업데이트 하는 방식으로 학습을 진행하는 방법으로 속도가 빠르다는 장점이 있다. 

```python
def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):
    """
    grid search function to select the best model based on RMSE of
    validation data
    Parameters
    ----------
    train_data: spark DF with columns ['userId', 'movieId', 'rating']
    
    validation_data: spark DF with columns ['userId', 'movieId', 'rating']
    
    maxIter: int, max number of learning iterations
    
    regParams: list of float, one dimension of hyper-param tuning grid
    
    ranks: list of float, one dimension of hyper-param tuning grid
    
    Return
    ------
    The best fitted ALS model with lowest RMSE score on validation data
    """
    # initial
    min_error = float('inf')
    best_rank = -1
    best_regularization = 0
    best_model = None
    for rank in ranks:
        for reg in regParams:
            # get ALS model
            als = ALS().setMaxIter(maxIter).setRank(rank).setRegParam(reg)
            # train ALS model
            model = als.fit(train_data)
            # evaluate the model by computing the RMSE on the validation data
            predictions = model.transform(validation_data)
            evaluator = RegressionEvaluator(metricName="rmse",
                                            labelCol="rating",
                                            predictionCol="prediction")
            rmse = evaluator.evaluate(predictions)
            print('{} latent factors and regularization = {}: '
                  'validation RMSE is {}'.format(rank, reg, rmse))
            if rmse < min_error:
                min_error = rmse
                best_rank = rank
                best_regularization = reg
                best_model = model
    print('\nThe best model has {} latent factors and '
          'regularization = {}'.format(best_rank, best_regularization))
    return best_model
``` 
## ALS

SGD 와 동일한 손실함수를 취하지만, loss function이 convex하지 않은 경우 발생하는 문제를 해결하기 위하여 두 개의 factorized행렬에 중 하나를 고정해 놓고 식을 quadratic(2차)식으로 변경하여 최적화하는 방식을 취한다.

# 4. 추가 내용
## Adding Bias
아이템과 유저간의 상호작용에 의해 발생된 것이 아닌 아이템과 유저 자체의 특성과 관련된 것을 Bias라고 부른다. 

**Adding Bias**란 이러한 부분을 모델에 넣어 더 정확한 예측을 가능하게 하는것을 말한다.

## Additional Input Sources
과거 경험이 존재하지 않아 생기는 문제를 Cold Start Problem이라고 하는데, 사용자에 대한 추가적인 정보 소스를 수집하여 이를 해결한다.

암시적 선호도를 N(u)로 정의하고 N(u) 아이템에 대한 선호도를 보인 사용자를 다음과 같이 표현하다.
-$\sum_{i \ in N}x_i$

그리고 유저가 가지고 있는 속성을 다음과 같이 정의한다.
-$\sum_{\alpha \ in A(u)}y_a$

## Temporal Dynamics
다음으로 시간의 흐름에 따라 변하는 상호관계를 반영되도록 다음과 같이 모델을 개선한다.

## Inputs with Varying Cofidence Levels
유저가 평가한 점수에 대한 신뢰도 점수를 부여하여, 정확한 예측을 가능하다록 한다.





































