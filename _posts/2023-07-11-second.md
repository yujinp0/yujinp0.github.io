---
layout: single
title:  "Matrix Factorization Technique for Recommender System"
typora-root-url: ../
categories: study
published: true
tag: [Recommend System, python, study]
toc: true
author_profile: false
sidebar: 
nav: "docs"
---
# [논문 리뷰 스터디 2] Recommand System

추천시스템은 유저와 아이템의 주변정보와 상호작용 기록을 바탕으로 유저가 선호할 아이템을 예측하여 유저의 의사결정을 돕는 인공지능 서비스이며, 아래와 같은 특징을 가지고 있다.

- 유저의 측면에서 원하는 것을 빠르게 찾을 수 있음
- 기업 측면에서는 고객 이탈을 막고, 반응 고객을 찾아내어 매출을 올릴 수 있음
- 행동패턴, 구매패턴, 메타 정보 활용
- 후보 생성, 순위 매기기, 재정렬의 파이프라인을 가짐

추천시스템 관련 논문 중 오늘 리뷰할 논문은 "Matrix Factorization Technique for Recommender System"이다.
(논문 출처: https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf)

해당 논문에서 제시한 방식은 **협업 필터링**을 이용한 방법으로 사용자의 과거 경험과 행동 방식을 기반으로 한다. 따라서 과거 경험이 없는 경우 사용할 수 없다는 단점이 존재한(이를 보완하여 고안된 방법은 Factorization Machine). 협업 필터링은 잠재요인 모델과 근접 이웃 방법이 있으며 본 논문에서는 잠재요인 모델을 사용하였다. 

행렬 분해를 통하여 사용자의 과거 경험 데이터에서 패턴을 찾아내는데, 이를 적절하게 추청할 경우 주어진 데이터에서는 알 수 없던 숨겨진 특징을 발견할 수 있는 것으로 알려져 있다.

  
# 1. 행렬 분해 
각 유저가 아이템에 대해 매긴 평점, 혹은 구매/ 클릭 여부를 나타낸 행렬을 **Interaction Matrix**라고 하는데, 행렬에 유저의 직접적/ 간접적인 선호가 드러나 있다.

![image](https://github.com/yujinp0/yujinp0.github.io/assets/138744622/7a3cffa4-fa4a-4114-aafb-994bbc4f7cf9){: width="70%" height="70%"}{: .align-center}

출처: https://buomsoo-kim.github.io/data/images/2020-09-25/0.png

**Interaction Matrix**를 **User Latent Factor**와 **Item Latent Factor** 분해하는 것을 **Matrix Factorization**라고 한다. **Factorization을** 통하여 행렬을 저차원의 행렬로 쪼개어 연산의 효율성을 확보할 수 있으며, 노이즈를 줄이고 데이터를 압축하는 방향으로 계산하기 때문에 얻고자 하는 중요한 패턴에 집중할 수 있다는 이점이 있다. 

![image](https://github.com/yujinp0/yujinp0.github.io/assets/138744622/50797d70-dfa3-44d4-bcd7-e1572125216b)

출처: https://buomsoo-kim.github.io/data/images/2020-09-25/1.png{: width="70%" height="70%"}{: .align-center}

![image](https://github.com/yujinp0/yujinp0.github.io/assets/138744622/afc20204-8833-40de-9e61-ba3b70f2cbe4){: width="70%" height="70%"}{: .align-center}

출처: https://miro.medium.com/v2/resize:fit:720/format:webp/1*xMxQL_V9CWeLggrk-Uyzmg.png

# 2. 목표 함수
$$\min_{P, Q} \sum_{u,i \in k }^b (r_{ui}-p^T_uq_i)^2 + \lambda({||p_u||_2^2}+{||q_i||_2^2}) $$

 - $u, i$ \in T: user, item in Training Set
 - $r_ui$(ture rating)는 유저 u의 아이템 i$에 대한 평점
 - $p^T_uq_i(predictedr rating=666)$는 행렬 P와 Q에서 가져온 유저 u와 아이템 i에 대한 latent factor
 - $\lambda({||p_u||_2^2}+{||q_i||_2^2})$ regularization term으로 행렬의 값이 너무 커지지 않도록 하는 역할을 함

# 3. 최적화
손실함수를 최적화 하는 방법에는 **Stochastic Gradient Descent(SGD) 방법**과 **Alternating Least Squres(ALS) 방법**을 제시하고 있다.

## SGD
Gradient를 조금씩 업데이트 하는 방식으로 학습을 진행하는 방법으로 속도가 빠르다는 장접이 있지만, 

```python



def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):
    """
    grid search function to select the best model based on RMSE of
    validation data
    Parameters
    ----------
    train_data: spark DF with columns ['userId', 'movieId', 'rating']
    
    validation_data: spark DF with columns ['userId', 'movieId', 'rating']
    
    maxIter: int, max number of learning iterations
    
    regParams: list of float, one dimension of hyper-param tuning grid
    
    ranks: list of float, one dimension of hyper-param tuning grid
    
    Return
    ------
    The best fitted ALS model with lowest RMSE score on validation data
    """
    # initial
    min_error = float('inf')
    best_rank = -1
    best_regularization = 0
    best_model = None
    for rank in ranks:
        for reg in regParams:
            # get ALS model
            als = ALS().setMaxIter(maxIter).setRank(rank).setRegParam(reg)
            # train ALS model
            model = als.fit(train_data)
            # evaluate the model by computing the RMSE on the validation data
            predictions = model.transform(validation_data)
            evaluator = RegressionEvaluator(metricName="rmse",
                                            labelCol="rating",
                                            predictionCol="prediction")
            rmse = evaluator.evaluate(predictions)
            print('{} latent factors and regularization = {}: '
                  'validation RMSE is {}'.format(rank, reg, rmse))
            if rmse < min_error:
                min_error = rmse
                best_rank = rank
                best_regularization = reg
                best_model = model
    print('\nThe best model has {} latent factors and '
          'regularization = {}'.format(best_rank, best_regularization))
    return best_model
``` 
## ALS

SGD 와 동일한 손실함수를 취하지만, loss function이 convex하지 않은 경우에 발생하는 문제를 해결하기 위하여 두 개의 factorized행렬에 중 하나의 행렬을 고정해 놓고 다른 행렬을 최적화하는 방식을 취한다.

여기서








































